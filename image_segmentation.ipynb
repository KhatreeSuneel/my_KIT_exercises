{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2 as cv  # OpenCV for image processing\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "def load_json(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        train_id = data[\"Image IDs\"][\"Train Image IDs\"]\n",
    "        test_id = data[\"Image IDs\"][\"Test Image IDs\"]\n",
    "        label_map=data[\"Class Color Codes\"]\n",
    "        return train_id,test_id,label_map\n",
    "    \n",
    "path_json_config = '/Users/acer/Downloads/Deep learning in cv/Exercise 3/data/data-config.json'\n",
    "train_ids,test_ids,color_map= load_json(path_json_config)\n",
    "color_map\n",
    "def map_color2label(color_img,color_code):\n",
    "    lbl = np.zeros((color_img.shape[0],color_img.shape[1]),dtype=np.uint8)\n",
    "    for label,color in color_code.items():\n",
    "        mask = np.all(color_img==np.array(color),axis=-1)\n",
    "        lbl[mask]=label\n",
    "\n",
    "    return lbl\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dir, split,cmap, transform=None,label_transform=None):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.image_dir = os.path.join(self.root_dir, 'images')\n",
    "        self.label_dir = os.path.join(self.root_dir, 'labels')\n",
    "        self.cmap = cmap\n",
    "        self.transform = transform\n",
    "        self.label_transform = label_transform\n",
    "\n",
    "        # List of all image files\n",
    "        self.image_files = sorted(os.listdir(self.image_dir))\n",
    "        self.label_files = sorted(os.listdir(self.label_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image and label file paths\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.label_files[idx])\n",
    "\n",
    "        # Read the image and label\n",
    "        image = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        image  = Image.fromarray(image)\n",
    "        label = cv.imread(label_path,cv.IMREAD_COLOR)\n",
    "        label = cv.cvtColor(label, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        # map colors to label in label images\n",
    "        label = map_color2label(label,self.cmap)\n",
    "        label = Image.fromarray(label)\n",
    "\n",
    "        # # Convert image and label to float32\n",
    "        # image = image.astype(np.float32) / 255.0\n",
    "        # label = label.astype(np.float32) / 255.0\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.label_transform:\n",
    "            label = self.label_transform(label)\n",
    "\n",
    "            # label = self.transform(label)\n",
    "\n",
    "        return image, label\n",
    "class ToTensorWithoutScaling:\n",
    "    def __call__(self, img):\n",
    "        tensor =  torch.from_numpy(np.array(img)).long()\n",
    "        return tensor.unsqueeze(0)\n",
    "root = \"/Users/acer/Downloads/Deep learning in cv/Exercise 3/data/256_patch\"\n",
    "trans = transforms.ToTensor()\n",
    "lbl_trans = ToTensorWithoutScaling()\n",
    "training_dataset = SegmentationDataset(root_dir=root,split='train',cmap=color_map,transform=trans,label_transform=lbl_trans)\n",
    "test_datasets = SegmentationDataset(root_dir=root,split='test',cmap=color_map,transform=trans,label_transform=lbl_trans)\n",
    "training_dataloader = DataLoader(training_dataset,batch_size=8,shuffle=True)\n",
    "test_dataloader = DataLoader(test_datasets,batch_size=8,shuffle=True)\n",
    "\n",
    "\n",
    "batch = next(iter(training_dataloader))\n",
    "images, labels = batch\n",
    "labels[0]\n",
    "\n",
    "# def show_images(loader):\n",
    "#     batch = next(iter(loader))\n",
    "#     images, labels = batch\n",
    "    \n",
    "#     grid = torchvision.utils.make_grid((labels*50), nrow = 8)\n",
    "#     plt.figure(figsize=(11,11))\n",
    "#     plt.imshow(np.transpose(grid,(1,2,0)))\n",
    "#     # print('labels: ', labels)\n",
    "\n",
    "def show_images(loader):\n",
    "    batch = next(iter(loader))\n",
    "    images, labels = batch\n",
    "    \n",
    "    grid = torchvision.utils.make_grid((images), nrow = 8, padding = 2)\n",
    "    label_grid = torchvision.utils.make_grid(labels*50, nrow=8, padding=2)\n",
    "    \n",
    "    # Plotting the images and labels\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 6))  # Create 2 rows, 1 column of subplots\n",
    "    \n",
    "    # Plot the image grid\n",
    "    axs[0].imshow(np.transpose(grid.numpy(), (1, 2, 0)))  # Convert from CxHxW to HxWxC\n",
    "    axs[0].set_title('Training Images')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Plot the label grid\n",
    "    axs[1].imshow(np.transpose(label_grid.numpy(), (1, 2, 0)))  # Convert from CxHxW to HxWxC\n",
    "    axs[1].set_title('Label Images')\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "show_images(training_dataloader)\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# an instance of custom segmentation model\n",
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "#         self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "#         self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "#         self.batch_norm2 = nn.BatchNorm2d(64)\n",
    "#         self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.batch_norm3 = nn.BatchNorm2d(128)\n",
    "#         self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "#         self.batch_norm4 = nn.BatchNorm2d(128)\n",
    "#         self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.batch_norm5 = nn.BatchNorm2d(256)\n",
    "#         self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "#         self.batch_norm6 = nn.BatchNorm2d(256)\n",
    "#         self.max_pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.batch_norm1(self.conv1(x)))\n",
    "#         x = torch.relu(self.batch_norm2(self.conv2(x)))\n",
    "#         x = self.max_pool1(x)\n",
    "\n",
    "#         x = torch.relu(self.batch_norm3(self.conv3(x)))\n",
    "#         x = torch.relu(self.batch_norm4(self.conv4(x)))\n",
    "#         x = self.max_pool2(x)\n",
    "\n",
    "#         x = torch.relu(self.batch_norm5(self.conv5(x)))\n",
    "#         x = torch.relu(self.batch_norm6(self.conv6(x)))\n",
    "#         x = self.max_pool3(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.upsample1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "#         self.conv7 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "#         self.batch_norm7 = nn.BatchNorm2d(128)\n",
    "\n",
    "#         self.upsample2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "#         self.conv8 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "#         self.batch_norm8 = nn.BatchNorm2d(64)\n",
    "\n",
    "#         self.upsample3 = nn.ConvTranspose2d(64, 6, kernel_size=2, stride=2)\n",
    "#         self.conv9 = nn.Conv2d(6, 6, kernel_size=3, padding=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.batch_norm7(self.conv7(self.upsample1(x))))\n",
    "#         x = torch.relu(self.batch_norm8(self.conv8(self.upsample2(x))))\n",
    "#         x = self.conv9(self.upsample3(x))\n",
    "\n",
    "#         return x\n",
    "\n",
    "# class SegNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SegNet, self).__init__()\n",
    "#         self.encoder = Encoder()\n",
    "#         self.decoder = Decoder()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.encoder(x)\n",
    "#         x = self.decoder(x)\n",
    "#         return x\n",
    "# model = SegNet().to(device)\n",
    "# print(model)\n",
    "import segmentation_models_pytorch as smp\n",
    "my_model = '/Users/acer/Downloads/Deep learning in cv/Exercise 3/models/unet_resnet18_3channels_25epochs_patchsize256.pt'\n",
    "model = torch.load(my_model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "print(model)\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    epoch_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(training_dataloader):\n",
    "        images =images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "      \n",
    "        outputs = outputs.permute(0, 2, 3, 1).contiguous()  # Ensure channel dimension is last\n",
    "        outputs = outputs.view(-1, outputs.size(3))\n",
    "        \n",
    "        labels = labels.view(-1) \n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        epoch_correct += correct\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    # Average epoch loss and accuracy\n",
    "    avg_loss = epoch_loss / len(training_dataloader)\n",
    "    accuracy = epoch_correct / total_samples\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    # Initialize variables for predictions and true labels\n",
    "    all_predicted_labels = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate predicted labels by finding the class with the max score\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        # Flatten the predicted and true labels\n",
    "        predicted = predicted.view(-1).cpu().numpy()\n",
    "        labels = labels.view(-1).cpu().numpy()\n",
    "        \n",
    "        # Update predicted labels and true labels\n",
    "        all_predicted_labels.extend(predicted)\n",
    "        all_true_labels.extend(labels)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_predicted_labels = np.array(all_predicted_labels)\n",
    "all_true_labels = np.array(all_true_labels)\n",
    "\n",
    "# Calculate precision, recall, F1-score, and overall accuracy\n",
    "classification_rep = classification_report(all_true_labels, all_predicted_labels, zero_division=1)\n",
    "confusion_mat = confusion_matrix(all_true_labels, all_predicted_labels)\n",
    "\n",
    "# Print the results\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print()\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Define a function to convert label images to color images\n",
    "def label2color(label_img, color_code):\n",
    "    \n",
    "    # Create an empty RGB image\n",
    "    color_img = np.zeros((label_img.shape[0], label_img.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    for label, color in color_code.items():\n",
    "        mask = label_img == int(label)  # Create a mask for the current class label\n",
    "        color_img[mask] = color  # Assign the corresponding RGB color\n",
    "    \n",
    "    return color_img\n",
    "test_img = '/Users/acer/Downloads/Deep learning in cv/Exercise 3/data/256_patch/test/images/area30_patch50.tif'\n",
    "lbl_img = '/Users/acer/Downloads/Deep learning in cv/Exercise 3/data/256_patch/test/labels/area30_patch50.tif'\n",
    "\n",
    "# Load the image, prediction and label for a sample image visualization\n",
    "def segmentation(src,lbl):\n",
    "    images = cv.cvtColor((cv.imread(src,cv.IMREAD_COLOR)),cv.COLOR_BGR2RGB)\n",
    "    label = cv.cvtColor((cv.imread(lbl,cv.IMREAD_COLOR)),cv.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(images)\n",
    "    label = Image.fromarray(label)\n",
    "    preprocess = transforms.Compose([ transforms.ToTensor()])\n",
    "    img = preprocess(img)\n",
    "    \n",
    "    \n",
    "    input_tensor = img.unsqueeze(0).to(device) \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _,predict = torch.max(output.data, 1)\n",
    "\n",
    "    predict = predict.squeeze().cpu().numpy()\n",
    "    predict = label2color(predict,color_map)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axes[0].imshow(images)\n",
    "    axes[1].imshow(predict)\n",
    "    axes[2].imshow(label)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "segmentation(test_img,lbl_img)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
